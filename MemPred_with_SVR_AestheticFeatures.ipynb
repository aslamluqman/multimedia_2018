{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "import pyprind\n",
    "from collections import Counter\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# for reproducability\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "\n",
    "\n",
    "def read_array(fname):\n",
    "    '''read an array from txt file'''\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            pairs = line.split(',')\n",
    "            #print(pairs)\n",
    "    return [float(item) for item in pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>AF_mean</th>\n",
       "      <th>AF_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video10.webm</td>\n",
       "      <td>[0.402878, 0.389358, 0.564687, 0.400378, 0.471...</td>\n",
       "      <td>[0.427258, 0.381448, 0.582746, 0.409475, 0.489...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video100.webm</td>\n",
       "      <td>[0.160705, 0.237773, 0.409616, 0.179789, 0.367...</td>\n",
       "      <td>[0.160579, 0.238155, 0.408475, 0.180416, 0.366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video10000.webm</td>\n",
       "      <td>[0.46136, 0.358996, 0.710791, 0.333263, 0.5849...</td>\n",
       "      <td>[0.461391, 0.358922, 0.710828, 0.333437, 0.585...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video10001.webm</td>\n",
       "      <td>[0.105545, 0.60667, 0.569378, 0.515591, 0.4109...</td>\n",
       "      <td>[0.105085, 0.606699, 0.567169, 0.51536, 0.4101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video10002.webm</td>\n",
       "      <td>[0.233127, 0.149484, 0.649683, 0.14423, 0.6057...</td>\n",
       "      <td>[0.232971, 0.149975, 0.649477, 0.143106, 0.605...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             video                                            AF_mean  \\\n",
       "0     video10.webm  [0.402878, 0.389358, 0.564687, 0.400378, 0.471...   \n",
       "1    video100.webm  [0.160705, 0.237773, 0.409616, 0.179789, 0.367...   \n",
       "2  video10000.webm  [0.46136, 0.358996, 0.710791, 0.333263, 0.5849...   \n",
       "3  video10001.webm  [0.105545, 0.60667, 0.569378, 0.515591, 0.4109...   \n",
       "4  video10002.webm  [0.233127, 0.149484, 0.649683, 0.14423, 0.6057...   \n",
       "\n",
       "                                           AF_median  \n",
       "0  [0.427258, 0.381448, 0.582746, 0.409475, 0.489...  \n",
       "1  [0.160579, 0.238155, 0.408475, 0.180416, 0.366...  \n",
       "2  [0.461391, 0.358922, 0.710828, 0.333437, 0.585...  \n",
       "3  [0.105085, 0.606699, 0.567169, 0.51536, 0.4101...  \n",
       "4  [0.232971, 0.149975, 0.649477, 0.143106, 0.605...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define paths of the Aesthetic Features\n",
    "path_AF_Mean = '/media/stone/Data/DataSet_me18me/me18me-devset/dev-set/features/aesthetic_visual_features/aesthetic_feat_dev-set_mean'\n",
    "path_AF_Median = '/media/stone/Data/DataSet_me18me/me18me-devset/dev-set/features/aesthetic_visual_features/aesthetic_feat_dev-set_median'\n",
    "\n",
    "# Load video related features first\n",
    "vn_mean = os.listdir(path_AF_Mean)\n",
    "\n",
    "# stack the video names in dataframe\n",
    "df = pd.DataFrame()\n",
    "df['video'] = [os.path.splitext(vn)[0]+'.webm' for vn in vn_mean]\n",
    "\n",
    "# read the aesthetic feat (mean and media) in dataframe\n",
    "df['AF_mean'] = [ read_array(path_AF_Mean+'/'+vn[:-5]+'.txt') for vn in df['video']]\n",
    "df['AF_median'] = [ read_array(path_AF_Median+'/'+vn[:-5]+'.txt') for vn in df['video']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>short-term_memorability</th>\n",
       "      <th>nb_short-term_annotations</th>\n",
       "      <th>long-term_memorability</th>\n",
       "      <th>nb_long-term_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video10.webm</td>\n",
       "      <td>0.950</td>\n",
       "      <td>34</td>\n",
       "      <td>0.900</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video100.webm</td>\n",
       "      <td>0.951</td>\n",
       "      <td>33</td>\n",
       "      <td>0.889</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video10000.webm</td>\n",
       "      <td>0.832</td>\n",
       "      <td>33</td>\n",
       "      <td>1.000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video10001.webm</td>\n",
       "      <td>0.865</td>\n",
       "      <td>33</td>\n",
       "      <td>0.727</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video10002.webm</td>\n",
       "      <td>0.899</td>\n",
       "      <td>59</td>\n",
       "      <td>0.792</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             video  short-term_memorability  nb_short-term_annotations  \\\n",
       "0     video10.webm                    0.950                         34   \n",
       "1    video100.webm                    0.951                         33   \n",
       "2  video10000.webm                    0.832                         33   \n",
       "3  video10001.webm                    0.865                         33   \n",
       "4  video10002.webm                    0.899                         59   \n",
       "\n",
       "   long-term_memorability  nb_long-term_annotations  \n",
       "0                   0.900                        10  \n",
       "1                   0.889                         9  \n",
       "2                   1.000                        13  \n",
       "3                   0.727                        11  \n",
       "4                   0.792                        24  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the ground truth values\n",
    "label_path = '/media/stone/Data/DataSet_me18me/me18me-devset/dev-set/ground-truth/'\n",
    "labels=pd.read_csv(label_path+'ground-truth_dev-set.csv')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>AF_mean</th>\n",
       "      <th>AF_median</th>\n",
       "      <th>short-term_memorability</th>\n",
       "      <th>nb_short-term_annotations</th>\n",
       "      <th>long-term_memorability</th>\n",
       "      <th>nb_long-term_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video10.webm</td>\n",
       "      <td>[0.402878, 0.389358, 0.564687, 0.400378, 0.471...</td>\n",
       "      <td>[0.427258, 0.381448, 0.582746, 0.409475, 0.489...</td>\n",
       "      <td>0.950</td>\n",
       "      <td>34</td>\n",
       "      <td>0.900</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video100.webm</td>\n",
       "      <td>[0.160705, 0.237773, 0.409616, 0.179789, 0.367...</td>\n",
       "      <td>[0.160579, 0.238155, 0.408475, 0.180416, 0.366...</td>\n",
       "      <td>0.951</td>\n",
       "      <td>33</td>\n",
       "      <td>0.889</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video10000.webm</td>\n",
       "      <td>[0.46136, 0.358996, 0.710791, 0.333263, 0.5849...</td>\n",
       "      <td>[0.461391, 0.358922, 0.710828, 0.333437, 0.585...</td>\n",
       "      <td>0.832</td>\n",
       "      <td>33</td>\n",
       "      <td>1.000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video10001.webm</td>\n",
       "      <td>[0.105545, 0.60667, 0.569378, 0.515591, 0.4109...</td>\n",
       "      <td>[0.105085, 0.606699, 0.567169, 0.51536, 0.4101...</td>\n",
       "      <td>0.865</td>\n",
       "      <td>33</td>\n",
       "      <td>0.727</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video10002.webm</td>\n",
       "      <td>[0.233127, 0.149484, 0.649683, 0.14423, 0.6057...</td>\n",
       "      <td>[0.232971, 0.149975, 0.649477, 0.143106, 0.605...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>59</td>\n",
       "      <td>0.792</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             video                                            AF_mean  \\\n",
       "0     video10.webm  [0.402878, 0.389358, 0.564687, 0.400378, 0.471...   \n",
       "1    video100.webm  [0.160705, 0.237773, 0.409616, 0.179789, 0.367...   \n",
       "2  video10000.webm  [0.46136, 0.358996, 0.710791, 0.333263, 0.5849...   \n",
       "3  video10001.webm  [0.105545, 0.60667, 0.569378, 0.515591, 0.4109...   \n",
       "4  video10002.webm  [0.233127, 0.149484, 0.649683, 0.14423, 0.6057...   \n",
       "\n",
       "                                           AF_median  short-term_memorability  \\\n",
       "0  [0.427258, 0.381448, 0.582746, 0.409475, 0.489...                    0.950   \n",
       "1  [0.160579, 0.238155, 0.408475, 0.180416, 0.366...                    0.951   \n",
       "2  [0.461391, 0.358922, 0.710828, 0.333437, 0.585...                    0.832   \n",
       "3  [0.105085, 0.606699, 0.567169, 0.51536, 0.4101...                    0.865   \n",
       "4  [0.232971, 0.149975, 0.649477, 0.143106, 0.605...                    0.899   \n",
       "\n",
       "   nb_short-term_annotations  long-term_memorability  nb_long-term_annotations  \n",
       "0                         34                   0.900                        10  \n",
       "1                         33                   0.889                         9  \n",
       "2                         33                   1.000                        13  \n",
       "3                         33                   0.727                        11  \n",
       "4                         59                   0.792                        24  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Align the labels with features according to name\n",
    "df_complete = pd.merge(df,labels,on='video')\n",
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.427258,  0.381448,  0.582746, ..., -0.27963 , -0.012414,\n",
       "         0.197281],\n",
       "       [ 0.160579,  0.238155,  0.408475, ...,  0.719529,  1.099627,\n",
       "         1.690907],\n",
       "       [ 0.461391,  0.358922,  0.710828, ...,  1.56886 ,  0.38056 ,\n",
       "        -1.09876 ],\n",
       "       ...,\n",
       "       [ 0.358854,  0.134898,  0.513471, ...,  1.503436,  0.299821,\n",
       "         0.341942],\n",
       "       [ 0.071911,  0.516086,  0.635375, ..., -0.199719,  0.394017,\n",
       "        -0.115456],\n",
       "       [ 0.560848,  0.06117 ,  0.627021, ...,  0.09347 ,  0.026843,\n",
       "         0.421589]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the AF_mean only\n",
    "X =np.array([col for col in df_complete['AF_median'].values ])\n",
    "Y = df_complete[['short-term_memorability','long-term_memorability']].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=124)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import KernelPCA, PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_pipline():\n",
    "    stdi = StandardScaler()\n",
    "    pca = PCA(n_components=0.98,svd_solver='full')\n",
    "    svr = svm.SVR(C=1.0,epsilon=0.01,kernel='rbf')\n",
    "    svr_pip = Pipeline([('standadizer',stdi),('pca',pca),('svr',svr)])\n",
    "    return svr_pip\n",
    "\n",
    "# predict the short-term and long-term memorability\n",
    "MP_svr_s = svr_pipline()\n",
    "MP_svr_l = svr_pipline()\n",
    "MP_svr_s.fit(X_train,Y_train[:,0])\n",
    "Y_pred_short=MP_svr_s.predict(X_test)\n",
    "\n",
    "MP_svr_l.fit(X_train,Y_train[:,1])\n",
    "Y_pred_long = MP_svr_l.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect results and calculate the score using Spearman's rank correlation\n",
    "res = pd.DataFrame()\n",
    "res['short_pred'] = Y_pred_short\n",
    "res['long_pred'] = Y_pred_long\n",
    "res['short_true'] = Y_test[:,0]\n",
    "res['long_true'] = Y_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_pred</th>\n",
       "      <th>short_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>short_pred</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.23782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_true</th>\n",
       "      <td>0.23782</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            short_pred  short_true\n",
       "short_pred     1.00000     0.23782\n",
       "short_true     0.23782     1.00000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[['short_pred','short_true']].corr(method='spearman',min_periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0637144478361168"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=res[['long_pred','long_true']].corr(method='spearman',min_periods=1)\n",
    "a.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_corr(x_pred,x_true):\n",
    "    \"The official performance matrix: Spearman's rank correlation\"\n",
    "    a = pd.DataFrame()\n",
    "    a['true'] = x_true\n",
    "    a['pred'] = x_pred\n",
    "    res = a[['true','pred']].corr(method='spearman',min_periods=1)\n",
    "    return res.iloc[0,1]\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "spearman = make_scorer(spearman_corr,greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2378199906344876"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearman_corr(Y_pred_short,Y_test[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'pca__n_components':[0.7,0.8,0.9,0.95],\n",
    "         'svr__C':[0.01,0.1,1,2,5],\n",
    "         'svr__epsilon':[0.01,0.1,0.2],\n",
    "         'svr__kernel':['rbf','poly']}\n",
    "A = GridSearchCV(MP_svr_s,params,scoring=spearman,cv=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-68:\n",
      "Process ForkPoolWorker-67:\n",
      "Process ForkPoolWorker-69:\n",
      "Process ForkPoolWorker-70:\n",
      "Process ForkPoolWorker-71:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4427c93fdf88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "A.fit(X,Y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = GridSearchCV(MP_svr_l,params,scoring=spearman,cv=3,n_jobs=-1)\n",
    "B.fit(X,Y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "# To serialize\n",
    "import pickle\n",
    "with open('svr_aesthetic_short.pkl', 'wb') as fid:\n",
    "    pickle.dump(A, fid)\n",
    "with open('svr_aesthetic_long.pkl','wb') as fid:\n",
    "    pickle.dump(B,fid)\n",
    "# To deserialize estimator later\n",
    "#with open('our_estimator.pkl', 'rb') as fid:\n",
    "#    gnb = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
